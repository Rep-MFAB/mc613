\section{Teoria}

No projeto, foi desenvolvido um circuito que realiza o algoritmo de regressão linear, 
que é um algoritmo comumente aplicado a Machine Learning. 
A motivação para tal circuito é mostrar que é possível, e prático, 
a manufatura de circuitos que executam esse algoritmo, 
sem a necessidade de implementá los através de uma linguagem de programação que 
irá exigir mais recursos em termos de hardware para operar.

A regressão linear é um método simples, que consiste em achar um mínimo (ou máximo) 
local de uma função, através do método gradiente e de uma função custo 
que utiliza do método dos mínimos quadrados.

Para realizar essa tarefa, iremos separar o processo em duas etapas que irão consistir em: 

\begin{itemize}
    \item passar dados com suas respectivas respostas esperadas e com isso calcular uma 
            função que será otimizada a medida que adicionamos mais dados, 
    \item Desenhar um gráfico da funçã gerada no monitor.
\end{itemize}

Para achar a função em questão, partiremos da função hipótese:

$$h_\theta (x) = \sum_{i=0}^{n} \theta_i x_i$$

Onde $x_i$ são as entradas, $n$ é o número de parâmetros e 
$\theta_i$ são os argumentos que queremos encontrar

A função de custo, que deve ser minimizada, se baseia no método
dos mínimos quadrados, sendo a função:

$$ J(\theta) = \frac{1}{2n}\sum_{i=i}^{n}(h_\theta (x_i) - y_i)^2$$

Onde $y_i$ é o resultado esperado para $x_i$

O método gradiente consiste em iterar sobre:

$$ \theta_i := \theta_i - 
    \alpha \frac{\partial}{\partial \theta_i} J(\theta)$$

Onde $\alpha$ é a taxa de aprendizado. Vale ressaltar que um $\alpha$ 
muito grande pode causar uma alta imprecisão, pois acabamos sempre pulando o mínimo, 
e um $\alpha$ muito pequeno pode gerar um tempo de execução muito longo, 
existem heurísticas para determinar $\alpha$, porém elas não serão abordadas
